{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probablistic model building genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ceph/users/zzhang/CRISPR_pred/crispr_kinn\n"
     ]
    }
   ],
   "source": [
    "%cd /mnt/ceph/users/zzhang/CRISPR_pred/crispr_kinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-1wnm72p4 because the default path (/home/zzhang/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected tf2 - using compatibility mode\n"
     ]
    }
   ],
   "source": [
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "from src.kinetic_model import KineticModel, modelSpace_to_modelParams, modelParams_to_modelSpace\n",
    "from src.neural_network_builder import KineticEigenModelBuilder, KineticNeuralNetworkBuilder\n",
    "#from src.model_spaces import get_informed_deplete_ms as get_model_space\n",
    "from src.model_spaces import get_cas9_finkelstein_ms_with_hidden as get_model_space\n",
    "\n",
    "from src.neural_search import search_env, get_reward_pipeline\n",
    "#from src.data import get_sim_ness_data as get_data\n",
    "from src.data import load_finkelstein_data as get_data\n",
    "# reload and re-train to full convergence\n",
    "from src.reload import reload_from_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T15:29:51.883107Z",
     "start_time": "2021-09-28T15:29:45.914227Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import shutil\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = get_data(logbase=10, include_ref=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup AMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.2\n"
     ]
    }
   ],
   "source": [
    "import amber\n",
    "print(amber.__version__)\n",
    "from amber.architect import pmbga\n",
    "from amber.architect import ModelSpace, Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSpace with 7 layers and 1 total combinations\n"
     ]
    }
   ],
   "source": [
    "kinn_model_space = get_model_space(use_sink_state=False)\n",
    "print(kinn_model_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filters': <amber.architect.pmbga.Categorical at 0x7fff7011f1c0>,\n",
       " 'SOURCE': '1',\n",
       " 'TARGET': '2',\n",
       " 'kernel_size': <amber.architect.pmbga.Categorical at 0x7fff700e90a0>,\n",
       " 'padding': 'same',\n",
       " 'EDGE': 1,\n",
       " 'RANGE_ST': <amber.architect.pmbga.Categorical at 0x7fffe8491a00>,\n",
       " 'RANGE_D': <amber.architect.pmbga.Categorical at 0x7fff700e92e0>,\n",
       " 'hidden_size': <amber.architect.pmbga.Categorical at 0x7fff7011f220>,\n",
       " 'reshape_fn': <amber.architect.pmbga.Categorical at 0x7fff7011f280>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kinn_model_space[2][0].Layer_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = pmbga.ProbaModelBuildGeneticAlgo(\n",
    "            model_space=kinn_model_space,\n",
    "            buffer_type='population',\n",
    "            buffer_size=50, # buffer size controlls the max history going back\n",
    "            batch_size=1,   # batch size does not matter in this case; all arcs will be retrieved\n",
    "            ewa_beta=0.9,  # ewa_beta approximates the moving average over 1/(1-ewa_beta) prev points\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A For-Loop that does the work for `amber.architect.trainEnv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = \"outputs/notebook\"\n",
    "# trainEnv parameters\n",
    "evo_params = dict(\n",
    "    model_fn = KineticNeuralNetworkBuilder,\n",
    "    #model_fn = KineticEigenModelBuilder,\n",
    "    samps_per_gen = 3,   # how many arcs to sample in each generation; important\n",
    "    max_gen = 200,\n",
    "    patience = 50,\n",
    "    n_warmup_gen = 0,\n",
    "    train_data = (x_train, y_train),\n",
    "    test_data = (x_test, y_test)\n",
    ")\n",
    "\n",
    "# manager configs\n",
    "# this learning rate is trickier than usual, for eigendecomp to work\n",
    "initial_learning_rate = 0.01\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10*int(7000/128), # decrease every 10 epochs\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "manager_kwargs={\n",
    "    'optimizer': lambda: tf.keras.optimizers.Adam(learning_rate=lr_schedule, clipnorm=1.),\n",
    "    'output_op': lambda: \n",
    "        tf.keras.layers.Lambda(lambda x: tf.math.log(tf.clip_by_value(x, 10**-5, 10**-1))/np.log(10), name=\"output_log\"),  # change the clip as well\n",
    "        #tf.keras.layers.Lambda(lambda x: tf.math.log(tf.clip_by_value(tf.reshape(- x[:,1], (-1,1)), 10**-5, 10**-1))/np.log(10), name=\"output_slice\"),\n",
    "    'n_feats': 25,  # remember to change this!!\n",
    "    'n_channels': 9,\n",
    "    'batch_size': 512,\n",
    "    'epochs': 50,\n",
    "    'earlystop': 10,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datapoints:  2 / total:  3\n",
      "[18:36:43] Gen 0 - Mean fitness 0.603 - Best 0.6871 - PostVar 5.291 - Time 18.04\n",
      "datapoints:  4 / total:  6\n",
      "[18:37:03] Gen 1 - Mean fitness 0.606 - Best 0.7001 - PostVar 5.224 - Time 20.44\n",
      "datapoints:  6 / total:  9\n",
      "[18:37:22] Gen 2 - Mean fitness 0.611 - Best 0.7340 - PostVar 5.245 - Time 18.59\n",
      "datapoints:  8 / total:  12\n",
      "[18:37:41] Gen 3 - Mean fitness 0.608 - Best 0.7340 - PostVar 5.074 - Time 18.65\n",
      "datapoints:  11 / total:  15\n",
      "[18:38:02] Gen 4 - Mean fitness 0.614 - Best 0.7340 - PostVar 5.218 - Time 20.89\n",
      "datapoints:  13 / total:  18\n",
      "[18:38:21] Gen 5 - Mean fitness 0.614 - Best 0.7340 - PostVar 5.426 - Time 19.65\n",
      "datapoints:  15 / total:  21\n",
      "[18:38:41] Gen 6 - Mean fitness 0.616 - Best 0.7340 - PostVar 5.281 - Time 19.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['serif'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Generic family 'serif' not found because none of the following families were found: Times New Roman\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user interrupted\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "save_controller() got an unexpected keyword argument 'wd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m controller, hist, stat_df \u001b[38;5;241m=\u001b[39m \u001b[43msearch_env\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontroller\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontroller\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevo_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevo_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmanager_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager_kwargs\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ceph/users/zzhang/CRISPR_pred/crispr_kinn/src/neural_search.py:110\u001b[0m, in \u001b[0;36msearch_env\u001b[0;34m(controller, wd, evo_params, manager_kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(wd, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward_vs_time.png\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# save\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m \u001b[43msave_controller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontroller\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# plot\u001b[39;00m\n\u001b[1;32m    113\u001b[0m make_plots(controller, canvas_nrow\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mceil(np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mlen\u001b[39m(controller\u001b[38;5;241m.\u001b[39mmodel_space))), wd\u001b[38;5;241m=\u001b[39mwd)\n",
      "\u001b[0;31mTypeError\u001b[0m: save_controller() got an unexpected keyword argument 'wd'"
     ]
    }
   ],
   "source": [
    "controller, hist, stat_df = search_env(\n",
    "    controller=controller, \n",
    "    wd = wd,\n",
    "    evo_params=evo_params, \n",
    "    manager_kwargs=manager_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(controller, open(os.path.join(wd, \"controller_states.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(hist).sort_values('test_reward', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join([str(x) \n",
    "                 for x in pd.DataFrame(hist).\n",
    "                 sort_values('test_reward', ascending=False).\n",
    "                 head(1)['arc'].values[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(hist)\n",
    "a['arc'] = ['|'.join([f\"{x.Layer_attributes['RANGE_ST']}-{x.Layer_attributes['RANGE_ST']+x.Layer_attributes['RANGE_D']}\" for x in entry]) for entry in a['arc']]\n",
    "a.drop(columns=['rate_df'], inplace=True)\n",
    "a.to_csv(os.path.join(wd,\"train_history.tsv\"), sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "ax = stat_df.plot.line(x='Generation', y=['GenAvg', 'Best'])\n",
    "ax.set_ylabel(\"Reward (Pearson correlation)\")\n",
    "ax.set_xlabel(\"Generation\")\n",
    "#plt.savefig(\"reward_vs_time.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth\n",
    "plot_gt = False\n",
    "with open(\"/mnt/home/alamson/ceph/DATA/CRISPR/KineticSims/22-05-12_cas9_kinn_deplete/cas9_kinn_deplete_params.yaml\", \"r\") as f:\n",
    "    gt_model_params = yaml.load(f, Loader=yaml.Loader)\n",
    "gt_model_params = modelParams_to_modelSpace(gt_model_params)\n",
    "gt_rates = [k for k in gt_model_params['Rates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START SITE\n",
    "fig, axs_ = plt.subplots(3,3, figsize=(15,15))\n",
    "axs = [axs_[i][j] for i in range(len(axs_)) for j in range(len(axs_[i]))]\n",
    "for k in controller.model_space_probs:\n",
    "    if k[-1] == 'RANGE_ST':\n",
    "        try:\n",
    "            d = controller.model_space_probs[k].sample(size=1000)\n",
    "        except:\n",
    "            continue\n",
    "        ax = axs[k[0]]\n",
    "        sns.distplot(d, label=\"Post\", ax=ax)\n",
    "        sns.distplot(controller.model_space_probs[k].prior_dist, label=\"Prior\", ax=ax)\n",
    "        if plot_gt:\n",
    "            ax.axvline(gt_rates[k[0]]['RANGE_ST'], ls='--', color='black')\n",
    "            ax.set_title(\n",
    "                f'Rate ID{str(k[0])} = {gt_rates[k[0]][\"name\"]}\\n'\n",
    "                f'Ground truth={gt_rates[k[0]][\"RANGE_ST\"]}\\nPosterior mean {str(np.mean(d))}')\n",
    "        else:\n",
    "            ax.set_title(\n",
    "                f'Rate ID{str(k[0])} = {gt_rates[k[0]][\"name\"]}\\n'\n",
    "                f'Posterior mean {str(np.mean(d))}')\n",
    "            \n",
    "\n",
    "        #_ = ax.set_xlim(0,50)\n",
    "\n",
    "fig.suptitle('range start')\n",
    "fig.tight_layout()\n",
    "#fig.savefig(\"range_st.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONV RANGE\n",
    "fig, axs_ = plt.subplots(3,3, figsize=(15,15))\n",
    "axs = [axs_[i][j] for i in range(len(axs_)) for j in range(len(axs_[i]))]\n",
    "for k in controller.model_space_probs:\n",
    "    if k[-1] == 'RANGE_D':\n",
    "        d = controller.model_space_probs[k].sample(size=1000)\n",
    "        ax = axs[k[0]]\n",
    "        sns.distplot(d, ax=ax)\n",
    "        sns.distplot(controller.model_space_probs[k].prior_dist, label=\"Prior\", ax=ax)\n",
    "        if plot_gt:\n",
    "            ax.axvline(gt_rates[k[0]]['RANGE_D'], ls='--', color='black')\n",
    "            ax.set_title(\n",
    "                f'Rate ID{str(k[0])} = {gt_rates[k[0]][\"name\"]}\\n'\n",
    "                f'Ground truth={gt_rates[k[0]][\"RANGE_D\"]}\\nPosterior mean {str(np.mean(d))}')\n",
    "        else:\n",
    "            ax.set_title(\n",
    "                f'Rate ID{str(k[0])} = {gt_rates[k[0]][\"name\"]}\\n'\n",
    "                f'Posterior mean {str(np.mean(d))}')\n",
    "\n",
    "fig.suptitle('range length')\n",
    "fig.tight_layout()\n",
    "#fig.savefig(\"range_d.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KERNEL SIZE \n",
    "fig, axs_ = plt.subplots(3,3, figsize=(15,15))\n",
    "axs = [axs_[i][j] for i in range(len(axs_)) for j in range(len(axs_[i]))]\n",
    "for k in controller.model_space_probs:\n",
    "    if k[-1] == 'kernel_size':\n",
    "        d = controller.model_space_probs[k].sample(size=1000)\n",
    "        ax = axs[k[0]]\n",
    "        sns.distplot(d, ax=ax)\n",
    "        sns.distplot(controller.model_space_probs[k].prior_dist, ax=ax)\n",
    "        ax.set_title(\n",
    "            ' '.join(['Rate ID', str(k[0]), '\\nPosterior mean', str(np.mean(d))]))\n",
    "        #_ = ax.set_xlim(0,20) \n",
    "fig.suptitle('kernel_size')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN SIZE \n",
    "fig, axs_ = plt.subplots(3,3, figsize=(15,15))\n",
    "axs = [axs_[i][j] for i in range(len(axs_)) for j in range(len(axs_[i]))]\n",
    "for k in controller.model_space_probs:\n",
    "    if k[-1] == 'hidden_size':\n",
    "        d = controller.model_space_probs[k].sample(size=1000)\n",
    "        ax = axs[k[0]]\n",
    "        sns.distplot(d, ax=ax)\n",
    "        sns.distplot(controller.model_space_probs[k].prior_dist, ax=ax)\n",
    "        ax.set_title(\n",
    "            ' '.join(['Rate ID', str(k[0]), '\\nPosterior mean', str(np.mean(d))]))\n",
    "        #_ = ax.set_xlim(0,20) \n",
    "fig.suptitle('hidden_size')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.load(open(\"outputs/notebook/AmberSearchBestModel_config.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.neural_network_builder import KineticEigenModelBuilder\n",
    "tf.compat.v1.reset_default_graph()\n",
    "tf.compat.v1.experimental.output_all_intermediates(True)\n",
    "sess = tf.compat.v1.Session()\n",
    "mb = reload_from_dir(\n",
    "    wd=\"outputs/notebook\", \n",
    "    manager_kwargs=manager_kwargs,\n",
    "    sess=sess,\n",
    "    model_fn=evo_params['model_fn'])\n",
    "model = mb.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train_b = mb.blockify_seq_ohe(x_train)\n",
    "x_test_b = mb.blockify_seq_ohe(x_test)\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=os.path.join(wd,\"bestmodel.h5\"), mode='min', verbose=0, save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "earlystopper = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    mode='min',\n",
    "    patience=15,\n",
    "    verbose=0)\n",
    "\n",
    "#model.fit(x_train_b, y_train,\n",
    "#          batch_size=32,\n",
    "#          validation_split=0.2,\n",
    "#          callbacks=[checkpointer, earlystopper],\n",
    "#          epochs=225, \n",
    "#          verbose=2)\n",
    "#model.load_weights(os.path.join(wd,\"bestmodel.h5\"))\n",
    "y_hat = model.predict(x_test_b).flatten()\n",
    "test_pcc = ss.pearsonr(np.log10(np.maximum(y_hat, 10**-5)), np.log10(y_test))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[str(x.__dict__) for x in mb.kinn.rates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict = {l.name:l for l in model.layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_id = \"conv_k0\"\n",
    "print(np.around(layer_dict[layer_id].get_weights()[0],3))\n",
    "print(np.around(layer_dict[layer_id].get_weights()[1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_id = \"conv_k1\"\n",
    "print(np.around(layer_dict[layer_id].get_weights()[0],3))\n",
    "print(np.around(layer_dict[layer_id].get_weights()[1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_id = \"conv_k2\"\n",
    "print(np.around(layer_dict[layer_id].get_weights()[0],3))\n",
    "print(np.around(layer_dict[layer_id].get_weights()[1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_id = \"conv_k3\"\n",
    "print(np.around(layer_dict[layer_id].get_weights()[0],3))\n",
    "print(np.around(layer_dict[layer_id].get_weights()[1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_id = \"conv_k4\"\n",
    "print(np.around(layer_dict[layer_id].get_weights()[0],3))\n",
    "print(np.around(layer_dict[layer_id].get_weights()[1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_id = \"conv_k5\"\n",
    "print(np.around(layer_dict[layer_id].get_weights()[0],3))\n",
    "print(np.around(layer_dict[layer_id].get_weights()[1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_id = \"conv_k6\"\n",
    "print(np.around(layer_dict[layer_id].get_weights()[0],3))\n",
    "print(np.around(layer_dict[layer_id].get_weights()[1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_test_b = mb.blockify_seq_ohe(x_test)\n",
    "y_hat = model.predict(x_test_b).flatten()\n",
    "h = sns.jointplot(y_test, y_hat)\n",
    "h.set_axis_labels(\"obs\", \"pred\", fontsize=16)\n",
    "print(\"spearman\", ss.spearmanr(y_hat, y_test))\n",
    "p = ss.pearsonr(y_hat, y_test)\n",
    "print(\"pearson\", p)\n",
    "h.fig.suptitle(\"Testing prediction, pcc=%.3f\"%p[0], fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
