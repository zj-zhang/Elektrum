{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probablistic model building genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ceph/users/zzhang/CRISPR_pred/crispr_kinn\n"
     ]
    }
   ],
   "source": [
    "%cd /mnt/ceph/users/zzhang/CRISPR_pred/crispr_kinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-g52v_n92 because the default path (/home/zzhang/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected tf2 - using compatibility mode\n"
     ]
    }
   ],
   "source": [
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "from src.kinetic_model import KineticModel, modelSpace_to_modelParams, modelParams_to_modelSpace\n",
    "from src.neural_network_builder import KineticEigenModelBuilder\n",
    "from src.model_spaces import get_informed_ms as get_model_space\n",
    "#from src.model_spaces import get_cas9_finkelstein_ms as get_model_space\n",
    "from src.neural_search import search_env, get_reward_pipeline\n",
    "from src.data import get_sim_ness_data as get_data\n",
    "#from src.data import load_finkelstein_data as get_data\n",
    "# reload and re-train to full convergence\n",
    "from src.reload import reload_from_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-28T15:29:51.883107Z",
     "start_time": "2021-09-28T15:29:45.914227Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import shutil\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup AMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.2\n"
     ]
    }
   ],
   "source": [
    "import amber\n",
    "print(amber.__version__)\n",
    "from amber.architect import pmbga\n",
    "from amber.architect import ModelSpace, Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSpace with 7 layers and 1 total combinations\n"
     ]
    }
   ],
   "source": [
    "kinn_model_space = get_model_space()\n",
    "print(kinn_model_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = pmbga.ProbaModelBuildGeneticAlgo(\n",
    "            model_space=kinn_model_space,\n",
    "            buffer_type='population',\n",
    "            buffer_size=50, # buffer size controlls the max history going back\n",
    "            batch_size=1,   # batch size does not matter in this case; all arcs will be retrieved\n",
    "            ewa_beta=0.8,  # ewa_beta approximates the moving average over 1/(1-ewa_beta) prev points\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A For-Loop that does the work for `amber.architect.trainEnv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = \"outputs/notebook\"\n",
    "# trainEnv parameters\n",
    "evo_params = dict(\n",
    "    model_fn = KineticEigenModelBuilder,\n",
    "    samps_per_gen = 10,   # how many arcs to sample in each generation; important\n",
    "    max_gen = 100,\n",
    "    patience = 100,\n",
    "    n_warmup_gen = 1,\n",
    "    train_data = (x_train, y_train),\n",
    "    test_data = (x_test, y_test)\n",
    ")\n",
    "\n",
    "# manager configs\n",
    "# this learning rate is trickier than usual, for eigendecomp to work\n",
    "initial_learning_rate = 0.01\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10*int(7000/128), # decrease every 10 epochs\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "manager_kwargs={\n",
    "    'optimizer': lambda: tf.keras.optimizers.Adam(learning_rate=lr_schedule, clipnorm=1.0),\n",
    "    'output_op': lambda: tf.keras.layers.Lambda(\n",
    "        lambda x: tf.math.log(tf.math.maximum(tf.reshape(- x[:,1], (-1,1)), 10**-10)),  # change the clip as well\n",
    "        name=\"output_slice\"),\n",
    "    'n_feats': 50,  # remember to change this!!\n",
    "    'n_channels': 9,\n",
    "    'batch_size': 128,\n",
    "    'epochs': 100,\n",
    "    'earlystop': 10,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 0 < 1 warmup.. skipped - Time 266.48\n",
      "datapoints:  12 / total:  20\n",
      "[20:38:36] Gen 1 - Mean fitness 0.775 - Best 0.9478 - PostVar 5.499 - Time 283.65\n",
      "0.774542857916648 * 0.8 + (1. - 0.8) * 0.8141389618507194\n",
      "datapoints:  19 / total:  30\n",
      "[20:43:29] Gen 2 - Mean fitness 0.782 - Best 0.9478 - PostVar 5.454 - Time 292.24\n",
      "0.7824620787034623 * 0.8 + (1. - 0.8) * 0.8567375879937215\n",
      "datapoints:  24 / total:  40\n",
      "[20:48:28] Gen 3 - Mean fitness 0.797 - Best 0.9478 - PostVar 5.162 - Time 299.25\n",
      "0.7973171805615141 * 0.8 + (1. - 0.8) * 0.811450481688823\n",
      "datapoints:  31 / total:  50\n",
      "[20:51:59] Gen 4 - Mean fitness 0.800 - Best 0.9478 - PostVar 5.172 - Time 210.71\n",
      "0.800143840786976 * 0.8 + (1. - 0.8) * 0.7775228181574266\n",
      "datapoints:  39 / total:  60\n",
      "[20:55:47] Gen 5 - Mean fitness 0.796 - Best 0.9479 - PostVar 5.293 - Time 228.62\n",
      "0.7956196362610661 * 0.8 + (1. - 0.8) * 0.8464422521044073\n",
      "datapoints:  46 / total:  70\n",
      "[20:59:22] Gen 6 - Mean fitness 0.806 - Best 0.9479 - PostVar 5.221 - Time 215.16\n",
      "0.8057841594297344 * 0.8 + (1. - 0.8) * 0.8219348257456252\n",
      "datapoints:  51 / total:  80\n",
      "[21:02:43] Gen 7 - Mean fitness 0.809 - Best 0.9479 - PostVar 5.349 - Time 200.74\n",
      "0.8090142926929125 * 0.8 + (1. - 0.8) * 0.893116832400638\n",
      "datapoints:  54 / total:  90\n",
      "[21:07:04] Gen 8 - Mean fitness 0.826 - Best 0.9479 - PostVar 5.425 - Time 260.67\n",
      "0.8258348006344576 * 0.8 + (1. - 0.8) * 0.8644738911304989\n",
      "datapoints:  58 / total:  100\n",
      "[21:11:31] Gen 9 - Mean fitness 0.834 - Best 0.9510 - PostVar 5.317 - Time 266.54\n",
      "0.8335626187336659 * 0.8 + (1. - 0.8) * 0.8482869254741748\n",
      "datapoints:  63 / total:  110\n",
      "[21:15:30] Gen 10 - Mean fitness 0.837 - Best 0.9510 - PostVar 5.179 - Time 239.77\n",
      "0.8365074800817677 * 0.8 + (1. - 0.8) * 0.8222597579103323\n",
      "datapoints:  73 / total:  120\n",
      "[21:19:54] Gen 11 - Mean fitness 0.834 - Best 0.9510 - PostVar 5.254 - Time 263.45\n",
      "0.8336579356474807 * 0.8 + (1. - 0.8) * 0.8299625649528583\n",
      "datapoints:  80 / total:  130\n",
      "[21:23:30] Gen 12 - Mean fitness 0.833 - Best 0.9510 - PostVar 4.973 - Time 215.69\n",
      "0.8329188615085562 * 0.8 + (1. - 0.8) * 0.8796374420231107\n",
      "datapoints:  81 / total:  140\n",
      "[21:27:55] Gen 13 - Mean fitness 0.842 - Best 0.9520 - PostVar 5.299 - Time 265.22\n",
      "0.8422625776114672 * 0.8 + (1. - 0.8) * 0.8882372321727636\n",
      "datapoints:  84 / total:  150\n",
      "[21:32:40] Gen 14 - Mean fitness 0.851 - Best 0.9520 - PostVar 5.395 - Time 284.76\n",
      "0.8514575085237265 * 0.8 + (1. - 0.8) * 0.880381655391638\n",
      "datapoints:  93 / total:  160\n",
      "[21:36:58] Gen 15 - Mean fitness 0.857 - Best 0.9520 - PostVar 5.114 - Time 258.10\n",
      "0.8572423378973087 * 0.8 + (1. - 0.8) * 0.9157574972360851\n",
      "datapoints:  92 / total:  170\n",
      "[21:41:44] Gen 16 - Mean fitness 0.869 - Best 0.9542 - PostVar 5.333 - Time 285.78\n",
      "0.868945369765064 * 0.8 + (1. - 0.8) * 0.8862235776919718\n",
      "datapoints:  96 / total:  180\n",
      "[21:45:04] Gen 17 - Mean fitness 0.872 - Best 0.9542 - PostVar 5.254 - Time 200.35\n",
      "0.8724010113504455 * 0.8 + (1. - 0.8) * 0.8818090245906317\n",
      "datapoints:  98 / total:  190\n",
      "[21:49:23] Gen 18 - Mean fitness 0.874 - Best 0.9542 - PostVar 5.430 - Time 259.07\n",
      "0.8742826139984827 * 0.8 + (1. - 0.8) * 0.8964933844484163\n",
      "datapoints:  96 / total:  200\n",
      "[21:53:23] Gen 19 - Mean fitness 0.879 - Best 0.9559 - PostVar 4.902 - Time 240.31\n",
      "0.8787247680884694 * 0.8 + (1. - 0.8) * 0.9015963798334845\n",
      "datapoints:  98 / total:  210\n",
      "[21:59:14] Gen 20 - Mean fitness 0.883 - Best 0.9559 - PostVar 4.767 - Time 350.24\n",
      "0.8832990904374725 * 0.8 + (1. - 0.8) * 0.8511615600337367\n",
      "datapoints:  113 / total:  220\n",
      "[22:03:56] Gen 21 - Mean fitness 0.877 - Best 0.9559 - PostVar 4.859 - Time 282.01\n",
      "0.8768715843567253 * 0.8 + (1. - 0.8) * 0.8857393467441501\n",
      "datapoints:  115 / total:  230\n",
      "[22:08:21] Gen 22 - Mean fitness 0.879 - Best 0.9559 - PostVar 4.942 - Time 265.08\n",
      "0.8786451368342103 * 0.8 + (1. - 0.8) * 0.8810177407019391\n",
      "datapoints:  117 / total:  240\n",
      "[22:12:37] Gen 23 - Mean fitness 0.879 - Best 0.9559 - PostVar 4.735 - Time 256.19\n",
      "0.879119657607756 * 0.8 + (1. - 0.8) * 0.8996953347538431\n",
      "datapoints:  119 / total:  250\n",
      "[22:17:00] Gen 24 - Mean fitness 0.883 - Best 0.9559 - PostVar 4.822 - Time 263.03\n",
      "0.8832347930369734 * 0.8 + (1. - 0.8) * 0.8438474530171508\n",
      "datapoints:  142 / total:  260\n",
      "[22:21:44] Gen 25 - Mean fitness 0.875 - Best 0.9559 - PostVar 5.188 - Time 283.66\n",
      "0.8753573250330089 * 0.8 + (1. - 0.8) * 0.900894902393856\n",
      "datapoints:  134 / total:  270\n",
      "[22:25:37] Gen 26 - Mean fitness 0.880 - Best 0.9559 - PostVar 4.914 - Time 232.67\n",
      "0.8804648405051783 * 0.8 + (1. - 0.8) * 0.87433083542389\n",
      "datapoints:  141 / total:  280\n",
      "[22:29:52] Gen 27 - Mean fitness 0.879 - Best 0.9559 - PostVar 4.681 - Time 255.01\n",
      "0.8792380394889207 * 0.8 + (1. - 0.8) * 0.8771329638310961\n",
      "datapoints:  151 / total:  290\n",
      "[22:35:03] Gen 28 - Mean fitness 0.879 - Best 0.9559 - PostVar 4.754 - Time 310.86\n",
      "0.8788170243573558 * 0.8 + (1. - 0.8) * 0.90033544474262\n",
      "datapoints:  148 / total:  300\n",
      "[22:39:24] Gen 29 - Mean fitness 0.883 - Best 0.9559 - PostVar 4.687 - Time 261.46\n",
      "0.8831207084344086 * 0.8 + (1. - 0.8) * 0.9112534664992562\n",
      "datapoints:  146 / total:  310\n",
      "[22:44:23] Gen 30 - Mean fitness 0.889 - Best 0.9559 - PostVar 4.810 - Time 299.39\n",
      "0.8887472600473781 * 0.8 + (1. - 0.8) * 0.9268444280120205\n",
      "datapoints:  144 / total:  320\n",
      "[22:48:57] Gen 31 - Mean fitness 0.896 - Best 0.9559 - PostVar 4.650 - Time 273.75\n",
      "0.8963666936403066 * 0.8 + (1. - 0.8) * 0.9039889309107373\n",
      "datapoints:  147 / total:  330\n",
      "[22:54:20] Gen 32 - Mean fitness 0.898 - Best 0.9559 - PostVar 4.822 - Time 322.45\n",
      "0.8978911410943928 * 0.8 + (1. - 0.8) * 0.9119990713532197\n",
      "datapoints:  149 / total:  340\n",
      "[22:58:48] Gen 33 - Mean fitness 0.901 - Best 0.9559 - PostVar 4.714 - Time 268.12\n",
      "0.9007127271461582 * 0.8 + (1. - 0.8) * 0.9116112970687876\n",
      "datapoints:  150 / total:  350\n",
      "[23:02:51] Gen 34 - Mean fitness 0.903 - Best 0.9559 - PostVar 4.687 - Time 242.57\n",
      "0.9028924411306841 * 0.8 + (1. - 0.8) * 0.9287551891883655\n",
      "datapoints:  151 / total:  360\n",
      "[23:07:39] Gen 35 - Mean fitness 0.908 - Best 0.9573 - PostVar 4.664 - Time 288.74\n",
      "0.9080649907422205 * 0.8 + (1. - 0.8) * 0.9017337834975162\n",
      "datapoints:  158 / total:  370\n",
      "[23:13:06] Gen 36 - Mean fitness 0.907 - Best 0.9573 - PostVar 4.364 - Time 326.54\n"
     ]
    }
   ],
   "source": [
    "controller, hist, stat_df = search_env(\n",
    "    controller=controller, \n",
    "    wd = wd,\n",
    "    evo_params=evo_params, \n",
    "    manager_kwargs=manager_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(hist).sort_values('test_reward', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join([str(x) \n",
    "                 for x in pd.DataFrame(hist).\n",
    "                 sort_values('test_reward', ascending=False).\n",
    "                 head(1)['arc'].values[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(hist)\n",
    "a['arc'] = ['|'.join([f\"{x.Layer_attributes['RANGE_ST']}-{x.Layer_attributes['RANGE_ST']+x.Layer_attributes['RANGE_D']}\" for x in entry]) for entry in a['arc']]\n",
    "a.drop(columns=['rate_df'], inplace=True)\n",
    "a.to_csv(os.path.join(wd,\"train_history.tsv\"), sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "ax = stat_df.plot.line(x='Generation', y=['GenAvg', 'Best'])\n",
    "ax.set_ylabel(\"Reward (Pearson correlation)\")\n",
    "ax.set_xlabel(\"Generation\")\n",
    "#plt.savefig(\"reward_vs_time.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth\n",
    "plot_gt = True\n",
    "with open(\"/mnt/home/alamson/ceph/DATA/CRISPR/KineticSims/22-05-12_cas9_kinn_deplete/cas9_kinn_deplete_params.yaml\", \"r\") as f:\n",
    "    gt_model_params = yaml.load(f, Loader=yaml.Loader)\n",
    "gt_model_params = modelParams_to_modelSpace(gt_model_params)\n",
    "gt_rates = [k for k in gt_model_params['Rates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START SITE\n",
    "fig, axs_ = plt.subplots(3,3, figsize=(15,15))\n",
    "axs = [axs_[i][j] for i in range(len(axs_)) for j in range(len(axs_[i]))]\n",
    "for k in controller.model_space_probs:\n",
    "    if k[-1] == 'RANGE_ST':\n",
    "        try:\n",
    "            d = controller.model_space_probs[k].sample(size=1000)\n",
    "        except:\n",
    "            continue\n",
    "        ax = axs[k[0]]\n",
    "        sns.distplot(d, label=\"Post\", ax=ax)\n",
    "        sns.distplot(controller.model_space_probs[k].prior_dist, label=\"Prior\", ax=ax)\n",
    "        if plot_gt:\n",
    "            ax.axvline(gt_rates[k[0]]['RANGE_ST'], ls='--', color='black')\n",
    "            ax.set_title(\n",
    "                f'Rate ID{str(k[0])} = {gt_rates[k[0]][\"name\"]}\\n'\n",
    "                f'Ground truth={gt_rates[k[0]][\"RANGE_ST\"]}\\nPosterior mean {str(np.mean(d))}')\n",
    "        else:\n",
    "            ax.set_title(\n",
    "                f'Rate ID{str(k[0])} = {gt_rates[k[0]][\"name\"]}\\n'\n",
    "                f'Posterior mean {str(np.mean(d))}')\n",
    "            \n",
    "\n",
    "        #_ = ax.set_xlim(0,50)\n",
    "\n",
    "fig.suptitle('range start')\n",
    "fig.tight_layout()\n",
    "#fig.savefig(\"range_st.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONV RANGE\n",
    "fig, axs_ = plt.subplots(3,3, figsize=(15,15))\n",
    "axs = [axs_[i][j] for i in range(len(axs_)) for j in range(len(axs_[i]))]\n",
    "for k in controller.model_space_probs:\n",
    "    if k[-1] == 'RANGE_D':\n",
    "        d = controller.model_space_probs[k].sample(size=1000)\n",
    "        ax = axs[k[0]]\n",
    "        sns.distplot(d, ax=ax)\n",
    "        sns.distplot(controller.model_space_probs[k].prior_dist, label=\"Prior\", ax=ax)\n",
    "        if plot_gt:\n",
    "            ax.axvline(gt_rates[k[0]]['RANGE_D'], ls='--', color='black')\n",
    "            ax.set_title(\n",
    "                f'Rate ID{str(k[0])} = {gt_rates[k[0]][\"name\"]}\\n'\n",
    "                f'Ground truth={gt_rates[k[0]][\"RANGE_D\"]}\\nPosterior mean {str(np.mean(d))}')\n",
    "        else:\n",
    "            ax.set_title(\n",
    "                f'Rate ID{str(k[0])} = {gt_rates[k[0]][\"name\"]}\\n'\n",
    "                f'Posterior mean {str(np.mean(d))}')\n",
    "\n",
    "fig.suptitle('range length')\n",
    "fig.tight_layout()\n",
    "#fig.savefig(\"range_d.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KERNEL SIZE \n",
    "fig, axs_ = plt.subplots(3,3, figsize=(15,15))\n",
    "axs = [axs_[i][j] for i in range(len(axs_)) for j in range(len(axs_[i]))]\n",
    "for k in controller.model_space_probs:\n",
    "    if k[-1] == 'kernel_size':\n",
    "        d = controller.model_space_probs[k].sample(size=1000)\n",
    "        ax = axs[k[0]]\n",
    "        sns.distplot(d, ax=ax)\n",
    "        sns.distplot(controller.model_space_probs[k].prior_dist, ax=ax)\n",
    "        ax.set_title(\n",
    "            ' '.join(['Rate ID', str(k[0]), '\\nPosterior mean', str(np.mean(d))]))\n",
    "        #_ = ax.set_xlim(0,20) \n",
    "fig.suptitle('kernel size')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickle.load(open(\"outputs/notebook/AmberSearchBestModel_config.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.neural_network_builder import KineticEigenModelBuilder\n",
    "tf.compat.v1.reset_default_graph()\n",
    "tf.compat.v1.experimental.output_all_intermediates(True)\n",
    "sess = tf.compat.v1.Session()\n",
    "mb = reload_from_dir(\n",
    "    wd=\"outputs/notebook\", \n",
    "    manager_kwargs=manager_kwargs,\n",
    "    sess=sess,\n",
    "    model_fn=KineticEigenModelBuilder)\n",
    "model = mb.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train_b = mb.blockify_seq_ohe(x_train)\n",
    "x_test_b = mb.blockify_seq_ohe(x_test)\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=os.path.join(wd,\"bestmodel.h5\"), mode='min', verbose=0, save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "earlystopper = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    mode='min',\n",
    "    patience=15,\n",
    "    verbose=0)\n",
    "\n",
    "#model.fit(x_train_b, y_train,\n",
    "#          batch_size=32,\n",
    "#          validation_split=0.2,\n",
    "#          callbacks=[checkpointer, earlystopper],\n",
    "#          epochs=225, \n",
    "#          verbose=2)\n",
    "#model.load_weights(os.path.join(wd,\"bestmodel.h5\"))\n",
    "y_hat = model.predict(x_test_b).flatten()\n",
    "test_pcc = ss.pearsonr(y_hat, y_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[str(x.__dict__) for x in mb.kinn.rates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict = {l.name:l for l in model.layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.around(layer_dict['conv_k0'].get_weights()[0],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.around(layer_dict['conv_k1'].get_weights()[0],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_test_b = mb.blockify_seq_ohe(x_test)\n",
    "y_hat = model.predict(x_test_b).flatten()\n",
    "h = sns.jointplot(np.log10(np.exp(y_test)), np.log10(np.exp(y_hat)))\n",
    "h.set_axis_labels(\"obs\", \"pred\", fontsize=16)\n",
    "print(\"spearman\", ss.spearmanr(y_hat, y_test))\n",
    "p = ss.pearsonr(y_hat, y_test)\n",
    "print(\"pearson\", p)\n",
    "h.fig.suptitle(\"Testing prediction, pcc=%.3f\"%p[0], fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
